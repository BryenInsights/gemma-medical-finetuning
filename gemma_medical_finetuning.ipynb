{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "aac98f21",
      "metadata": {
        "id": "aac98f21"
      },
      "source": [
        "# Fine‑tuning **Gemma‑3 Instruct (1 B)** on the *MTS‑Dialog* medical‑conversation dataset  \n",
        "\n",
        "*An end‑to‑end, LoRA‑based workflow with evaluation & demo*  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68e16b78",
      "metadata": {
        "id": "68e16b78"
      },
      "source": [
        "**Provenance / Credits**\n",
        "\n",
        "* Originally authored in Google Colab.  \n",
        "* Refactored and cleaned up for GitHub readability – May 2025.  \n",
        "* Dataset: **MTS‑Dialog** (© 2024, MIT‑licensed)  \n",
        "* Model: **Gemma‑3 Instruct 1 B** via `keras‑hub`.  \n",
        "\n",
        "> The notebook assumes Google Colab **or** a local machine with a modern GPU and official Gemma access.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f94a756a",
      "metadata": {
        "id": "f94a756a"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# ─── Environment setup ────────────────────────────────────────────────────────\n",
        "# Feel free to skip if these libraries are already installed.\n",
        "!pip install -q -U keras-hub keras keras-nlp rouge_score scipy tqdm ipywidgets"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d8b1dd2",
      "metadata": {
        "id": "6d8b1dd2"
      },
      "source": [
        "## 🔑 Reproducibility – set a single global RNG seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62fb9188",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download the utils.py file from the GitHub repository and charge it through Colab\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "44a8ef49",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44a8ef49",
        "outputId": "65060c7a-6127-41e9-d349-329a22e19f05"
      },
      "outputs": [],
      "source": [
        "import os, random, gc, json, textwrap\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "SEED = 42\n",
        "set_global_seed(SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "b127f1b4",
      "metadata": {
        "id": "b127f1b4"
      },
      "outputs": [],
      "source": [
        "# ─── Core libraries ──────────────────────────────────────────────────────────\n",
        "import pprint, itertools, math, time\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from scipy import stats\n",
        "from rouge_score import rouge_scorer\n",
        "# import torch\n",
        "\n",
        "import keras\n",
        "import keras_hub\n",
        "import keras_nlp\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "from utils import set_global_seed, estimate_tokens, clear_memory, filter_data_by_length, make_ds, compile_with_sampler, compile_for_training, safe_generate, evaluate_model\n",
        "\n",
        "# Optional: Colab‑only helper to pull your Kaggle creds from the browser\n",
        "try:\n",
        "    from google.colab import userdata  # type: ignore\n",
        "    os.environ[\"KAGGLE_USERNAME\"] = userdata.get(\"KAGGLE_USERNAME\")\n",
        "    os.environ[\"KAGGLE_KEY\"] = userdata.get(\"KAGGLE_KEY\")\n",
        "except (ImportError, ModuleNotFoundError):\n",
        "    print(\"Not on Colab – set $KAGGLE_USERNAME and $KAGGLE_KEY manually if needed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b339150a",
      "metadata": {
        "id": "b339150a"
      },
      "source": [
        "## 📝 Prompt template (single definition – DRY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "d60392af",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d60392af",
        "outputId": "ceafe600-e666-4433-beb2-8dcfd3b566a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<start_of_turn>user\n",
            "\n",
            "### Instruction:\n",
            "You are a clinical documentation assistant. Convert the doctor–patient conversation below into a concise clinical note. Include only medically relevant facts (symptoms, diagnoses, medications with dosages, procedures). Do not add commentary or conclusions.\n",
            "\n",
            "### Doctor-Patient Dialogue:\n",
            "{dialogue}\n",
            "<end_of_turn>\n",
            "\n",
            "<start_of_turn>assistant\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Using Gemma's native chat format for best performance\n",
        "TEMPLATE = \"\"\"<start_of_turn>user\n",
        "\n",
        "### Instruction:\n",
        "{instruction}\n",
        "\n",
        "### Doctor-Patient Dialogue:\n",
        "{dialogue}\n",
        "<end_of_turn>\n",
        "\n",
        "<start_of_turn>assistant\n",
        "\"\"\"\n",
        "\n",
        "instruction = (\n",
        "    \"You are a clinical documentation assistant. Convert the doctor–patient \"\n",
        "    \"conversation below into a concise clinical note. Include only medically \"\n",
        "    \"relevant facts (symptoms, diagnoses, medications with dosages, procedures). \"\n",
        "    \"Do not add commentary or conclusions.\"\n",
        ")\n",
        "\n",
        "formatted_template = TEMPLATE.format(instruction=instruction, dialogue=\"{dialogue}\")\n",
        "print(formatted_template)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46bb9dbc",
      "metadata": {
        "id": "46bb9dbc"
      },
      "source": [
        "### 🔍 Quick sanity‑check inference with the *base* Gemma model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "99fb90c6",
      "metadata": {
        "id": "99fb90c6"
      },
      "outputs": [],
      "source": [
        "clear_memory()\n",
        "\n",
        "base_model = keras_hub.models.Gemma3CausalLM.from_preset(\"gemma3_instruct_1b\")\n",
        "compile_with_sampler(base_model)\n",
        "\n",
        "sample_dialogue = \"\"\"Doctor: How are you feeling today?\n",
        "Patient: I'm still having chest pains.\n",
        "Doctor: Are they sharp or dull?\n",
        "Patient: More of a crushing pressure right here.\"\"\"\n",
        "\n",
        "prompt = TEMPLATE.format(\n",
        "    instruction=instruction,\n",
        "    dialogue= sample_dialogue\n",
        ")\n",
        "\n",
        "print(base_model.generate(prompt, max_length=1024))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "LHjZX2boiLC1",
      "metadata": {
        "id": "LHjZX2boiLC1"
      },
      "source": [
        "#### 🌐 Download the MTS-Dialog dataset\n",
        "###### You can skip this step if you already have the datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "T7RgFEhTiAnS",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7RgFEhTiAnS",
        "outputId": "41dc57d6-f676-4962-aaba-ba80367bd840"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import subprocess, sys, shutil\n",
        "\n",
        "DATA_REPO = \"https://github.com/abachaa/MTS-Dialog.git\"\n",
        "DATA_DIR  = Path(\"MTS-Dialog\") / \"Main-Dataset\"\n",
        "\n",
        "if DATA_DIR.exists():\n",
        "    print(f\"✅ Dataset already present at: {DATA_DIR.resolve()}\")\n",
        "else:\n",
        "    print(\"📥 Cloning MTS-Dialog repository (shallow)…\")\n",
        "    # --depth 1 keeps clone fast and lightweight\n",
        "    subprocess.run([\"git\", \"clone\", \"--depth\", \"1\", DATA_REPO], check=True)\n",
        "\n",
        "    if not DATA_DIR.exists():\n",
        "        sys.exit(\"❌ Dataset download failed - Main-Dataset not found.\")\n",
        "\n",
        "    print(f\"✅ Download complete! Data located at: {DATA_DIR.resolve()}\")\n",
        "\n",
        "# Make a handy constant the rest of the notebook can rely on\n",
        "DATA_PATH = DATA_DIR"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2458620d",
      "metadata": {
        "id": "2458620d"
      },
      "source": [
        "## 📚 Load & prepare the *MTS‑Dialog* training set\n",
        "\n",
        "*MTS‑Dialog* (`1.7 k` doctor–patient conversations with expert summaries).  \n",
        "Below we:  \n",
        "1. Fetch or load the CSV  \n",
        "2. (Optionally) **sample 500 rows** for a quick LoRA demo  \n",
        "3. Wrap dialogue text in triple quotes to preserve line breaks  \n",
        "4. Build two parallel lists `prompts` and `responses` expected by `keras‑hub`  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "f98abd29",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f98abd29",
        "outputId": "3586d5bc-a0ff-402d-907d-755f1eb56b6d"
      },
      "outputs": [],
      "source": [
        "# DATA_PATH = \"/content/MTS-Dialog-TrainingSet.csv\"  # adjust if running locally\n",
        "\n",
        "\n",
        "df = pd.read_csv(DATA_PATH / \"MTS-Dialog-TrainingSet.csv\")\n",
        "print(f\"💾 Loaded dataset with {len(df):,} rows\")\n",
        "\n",
        "# --- speed‑up during experimentation ---\n",
        "# df = df.sample(n=200, random_state=SEED)  # comment‑out for full training\n",
        "\n",
        "# --- minimal preprocessing ---\n",
        "df = df.dropna(subset=[\"dialogue\", \"section_text\"])\n",
        "\n",
        "# Remove rows where 'section_text' is very short\n",
        "df = df.query(\"section_text.str.len() > 30\", engine=\"python\")\n",
        "\n",
        "# Curly-quote normalisation\n",
        "df[\"section_text\"] = df[\"section_text\"].str.replace(\"’\", \"'\", regex=False)\n",
        "df[\"dialogue\"]      = df[\"dialogue\"].str.replace(\"’\", \"'\", regex=False)\n",
        "\n",
        "# Trim whitespace and add end token to 'section_text'\n",
        "df[\"section_text\"] = df[\"section_text\"].str.strip() + \"\\n<end_of_turn>\"\n",
        "\n",
        "# Trim whitespace\n",
        "df[\"dialogue\"] = df[\"dialogue\"].str.strip()\n",
        "print(f\"💾 Number of section texts after trimming and basic preprocessing: {len(df['section_text']):,} rows\") # Print after trimming\n",
        "\n",
        "prompts, responses = [], []\n",
        "for row in df.itertuples(index=False):\n",
        "    prompts.append(\n",
        "        TEMPLATE.format(instruction=instruction, dialogue=row.dialogue)\n",
        "    )\n",
        "    responses.append(row.section_text)\n",
        "\n",
        "# Stage 2: Token-length filtering (after prompt formatting)\n",
        "\n",
        "prompts, responses = filter_data_by_length(prompts, responses, max_input_tokens=1024)\n",
        "\n",
        "data = {'prompts': prompts, 'responses': responses}\n",
        "print(f\"✅ Prepared {len(prompts):,} filtered prompt/response pairs\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "RwwENwLwk5JK",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwwENwLwk5JK",
        "outputId": "c6a5d204-328f-4bec-bdce-6da996fa25b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Train samples: 831\n",
            "🔹 Val   samples: 92\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "47"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ─── 🗂️ Train/val split ➜ tf.data pipeline (memory-light) ──────────────\n",
        "VAL_FRACTION = 0.10\n",
        "rng = np.random.default_rng(SEED)\n",
        "\n",
        "prompts_arr   = np.array(data[\"prompts\"],    dtype=object)\n",
        "responses_arr = np.array(data[\"responses\"],  dtype=object)\n",
        "\n",
        "idx        = rng.permutation(len(prompts_arr))\n",
        "val_size   = int(len(idx) * VAL_FRACTION)\n",
        "val_idx, train_idx = idx[:val_size], idx[val_size:]\n",
        "\n",
        "train_data = make_ds(prompts_arr[train_idx], responses_arr[train_idx])\n",
        "val_data   = make_ds(prompts_arr[val_idx],   responses_arr[val_idx])\n",
        "\n",
        "print(f\"🔹 Train samples: {len(train_idx)}\")\n",
        "print(f\"🔹 Val   samples: {len(val_idx)}\")\n",
        "\n",
        "# —— immediately free the big NumPy arrays ——\n",
        "del prompts_arr, responses_arr, idx, train_idx, val_idx\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11ac89f7",
      "metadata": {
        "id": "11ac89f7"
      },
      "source": [
        "## 🔧 LoRA fine‑tuning\n",
        "\n",
        "> Mixed‑precision (`keras.mixed_precision.set_global_policy('mixed_bfloat16')`)  \n",
        "> can further reduce memory but is optional.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "7abd9bc8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "7abd9bc8",
        "outputId": "f970dcb7-0a41-42e3-d1d9-eac4a995b448"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Model compiled for training with AdamW optimizer (bias/scale excluded from weight decay)\n",
            "Epoch 1/8\n",
            "\u001b[1m831/831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1175s\u001b[0m 1s/step - loss: 0.1345 - sparse_categorical_accuracy: 0.5763 - val_loss: 0.1190 - val_sparse_categorical_accuracy: 0.6002\n",
            "Epoch 2/8\n",
            "\u001b[1m831/831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1119s\u001b[0m 1s/step - loss: 0.1198 - sparse_categorical_accuracy: 0.6205 - val_loss: 0.1179 - val_sparse_categorical_accuracy: 0.6078\n",
            "Epoch 3/8\n",
            "\u001b[1m831/831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1075s\u001b[0m 1s/step - loss: 0.0939 - sparse_categorical_accuracy: 0.6741 - val_loss: 0.1200 - val_sparse_categorical_accuracy: 0.6018\n",
            "💾  Saved LoRA adapters to lora_rank4_final.weights.lora.h5\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 500x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✔️  Fine-tuning complete; memory cleaned.\n"
          ]
        }
      ],
      "source": [
        "# 1️⃣  Clean up any leftover models/graphs\n",
        "clear_memory()\n",
        "\n",
        "# 2️⃣  Mixed-precision for speed & smaller activations\n",
        "keras.mixed_precision.set_global_policy(\"mixed_bfloat16\")\n",
        "\n",
        "# 3️⃣  Load Gemma-1B and enable LoRA\n",
        "gemma_lm = keras_hub.models.Gemma3CausalLM.from_preset(\"gemma3_instruct_1b\")\n",
        "gemma_lm.backbone.enable_lora(rank=16)\n",
        "\n",
        "# train & infer on 1024-token sequences (default was 256)\n",
        "gemma_lm.preprocessor.sequence_length = 1024\n",
        "\n",
        "compile_for_training(gemma_lm)\n",
        "\n",
        "# 4️⃣  Early stopping (no RAM-hungry weight snapshot)\n",
        "early_stop = keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_loss\", patience=1, min_delta=1e-3, restore_best_weights=False\n",
        ")\n",
        "\n",
        "# Simulate batch_size=4 with gradient accumulation\n",
        "gradient_accumulation_steps = 4\n",
        "\n",
        "# 5️⃣  Train\n",
        "history = gemma_lm.fit(\n",
        "    train_data,               # tf.data.Dataset from the split cell\n",
        "    validation_data=val_data,\n",
        "    epochs=8,                 # feel free to change\n",
        "    callbacks=[early_stop],\n",
        ")\n",
        "\n",
        "# 6️⃣  Save final LoRA adapters (tiny – a few MB)\n",
        "gemma_lm.backbone.save_lora_weights(\"lora_rank_16.weights.lora.h5\")\n",
        "print(\"💾  Saved LoRA adapters to lora_rank_16.weights.lora.h5\")\n",
        "\n",
        "# 7️⃣  Quick loss curve\n",
        "plt.figure(figsize=(5, 3))\n",
        "plt.plot(history.history[\"loss\"], \"o-\", label=\"train\")\n",
        "plt.plot(history.history.get(\"val_loss\", []), label=\"val\")\n",
        "plt.title(\"Loss\"); plt.xlabel(\"epoch\"); plt.legend(); plt.tight_layout()\n",
        "plt.show(); plt.close()\n",
        "\n",
        "# 8️⃣  Free heavy objects now that we’re done\n",
        "for obj in [\"train_data\", \"val_data\", \"history\"]:\n",
        "    if obj in globals():\n",
        "        del globals()[obj]\n",
        "gc.collect()\n",
        "\n",
        "print(\"✔️  Fine-tuning complete; memory cleaned.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5ebd708",
      "metadata": {
        "id": "d5ebd708"
      },
      "source": [
        "## 🔬 Validation set evaluation\n",
        "\n",
        "We compare the *base* and *fine‑tuned* checkpoints on the MTS‑Dialog validation split.  \n",
        "*(~25 min on a T4, ~8 min on an A100 – feel free to skip in a hurry.)*  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "12c2712e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "12c2712e",
        "outputId": "86603143-2f41-44ec-aed3-97cdbd6cb89b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📊 Kept 43 / 50 pairs (86.0%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating with Fine-tuned: 100%|██████████| 43/43 [04:43<00:00,  6.58s/it]\n",
            "Generating with Base: 100%|██████████| 43/43 [02:57<00:00,  4.13s/it]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style type=\"text/css\">\n",
              "</style>\n",
              "<table id=\"T_d9f0a\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_d9f0a_level0_col0\" class=\"col_heading level0 col0\" >Base</th>\n",
              "      <th id=\"T_d9f0a_level0_col1\" class=\"col_heading level0 col1\" >Fine-tuned</th>\n",
              "      <th id=\"T_d9f0a_level0_col2\" class=\"col_heading level0 col2\" >Δ</th>\n",
              "      <th id=\"T_d9f0a_level0_col3\" class=\"col_heading level0 col3\" >p-value</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th class=\"index_name level0\" >Metric</th>\n",
              "      <th class=\"blank col0\" >&nbsp;</th>\n",
              "      <th class=\"blank col1\" >&nbsp;</th>\n",
              "      <th class=\"blank col2\" >&nbsp;</th>\n",
              "      <th class=\"blank col3\" >&nbsp;</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_d9f0a_level0_row0\" class=\"row_heading level0 row0\" >ROUGE1</th>\n",
              "      <td id=\"T_d9f0a_row0_col0\" class=\"data row0 col0\" >0.4018</td>\n",
              "      <td id=\"T_d9f0a_row0_col1\" class=\"data row0 col1\" >0.4923</td>\n",
              "      <td id=\"T_d9f0a_row0_col2\" class=\"data row0 col2\" >0.0905</td>\n",
              "      <td id=\"T_d9f0a_row0_col3\" class=\"data row0 col3\" >0.0005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_d9f0a_level0_row1\" class=\"row_heading level0 row1\" >ROUGE2</th>\n",
              "      <td id=\"T_d9f0a_row1_col0\" class=\"data row1 col0\" >0.1769</td>\n",
              "      <td id=\"T_d9f0a_row1_col1\" class=\"data row1 col1\" >0.2573</td>\n",
              "      <td id=\"T_d9f0a_row1_col2\" class=\"data row1 col2\" >0.0805</td>\n",
              "      <td id=\"T_d9f0a_row1_col3\" class=\"data row1 col3\" >0.0004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_d9f0a_level0_row2\" class=\"row_heading level0 row2\" >ROUGEL</th>\n",
              "      <td id=\"T_d9f0a_row2_col0\" class=\"data row2 col0\" >0.3330</td>\n",
              "      <td id=\"T_d9f0a_row2_col1\" class=\"data row2 col1\" >0.4080</td>\n",
              "      <td id=\"T_d9f0a_row2_col2\" class=\"data row2 col2\" >0.0750</td>\n",
              "      <td id=\"T_d9f0a_row2_col3\" class=\"data row2 col3\" >0.0013</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7bbd2ec11bd0>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "VAL_PATH = DATA_PATH / \"MTS-Dialog-ValidationSet.csv\"\n",
        "val_df = pd.read_csv(VAL_PATH)\n",
        "\n",
        "# Optional speed-up during experimentation\n",
        "val_df = val_df.sample(n=50, random_state=SEED)\n",
        "\n",
        "prompts_val, references_val = [], []\n",
        "for row in val_df.itertuples(index=False):\n",
        "    prompts_val.append(TEMPLATE.format(instruction=instruction, dialogue=row.dialogue))\n",
        "    references_val.append(row.section_text)\n",
        "\n",
        "# Apply same filtering as training data\n",
        "prompts_val, references_val = filter_data_by_length(\n",
        "    prompts_val, references_val, max_input_tokens=1024\n",
        ")\n",
        "\n",
        "clear_memory()\n",
        "\n",
        "gemma_lm = keras_hub.models.Gemma3CausalLM.from_preset(\"gemma3_instruct_1b\")\n",
        "gemma_lm.backbone.enable_lora(rank=16)   # must match the saved rank\n",
        "gemma_lm.backbone.load_lora_weights(\"lora_rank_16.weights.lora.h5\")\n",
        "\n",
        "# ---------- 1. Evaluate the fine-tuned model first ----------\n",
        "fine_outputs, fine_scores, fine_metrics = evaluate_model(\n",
        "    gemma_lm, prompts_val, references_val, \"Fine-tuned\"\n",
        ")\n",
        "\n",
        "# Free GPU memory held by the tuned checkpoint\n",
        "del gemma_lm\n",
        "gc.collect()\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# ---------- 2. Evaluate a fresh base model ----------\n",
        "base_model = keras_hub.models.Gemma3CausalLM.from_preset(\"gemma3_instruct_1b\")\n",
        "compile_with_sampler(base_model, seed=SEED)\n",
        "\n",
        "base_outputs, base_scores, base_metrics = evaluate_model(\n",
        "    base_model, prompts_val, references_val, \"Base\"\n",
        ")\n",
        "\n",
        "# ---------- 3. Summarise the improvements ----------\n",
        "rows = []\n",
        "for metric in [\"rouge1\", \"rouge2\", \"rougeL\"]:\n",
        "    base_vals = base_scores[metric]\n",
        "    fine_vals = fine_scores[metric]\n",
        "    delta = np.mean(fine_vals) - np.mean(base_vals)\n",
        "    t_stat, p_val = stats.ttest_rel(fine_vals, base_vals)\n",
        "    rows.append((metric.upper(), np.mean(base_vals), np.mean(fine_vals), delta, p_val))\n",
        "\n",
        "results_df = pd.DataFrame(\n",
        "    rows, columns=[\"Metric\", \"Base\", \"Fine-tuned\", \"Δ\", \"p-value\"]\n",
        ").set_index(\"Metric\")\n",
        "\n",
        "results_df.style.format(\"{:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8813fa95",
      "metadata": {
        "id": "8813fa95"
      },
      "source": [
        "## 🔄 Quick Interactive Demo\n",
        "\n",
        "Paste a dialogue below and generate a clinical summary using the fine‑tuned Gemma model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "4a01428b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "4a01428b",
        "outputId": "b6e017ab-a7c2-4453-9622-7edafc240004"
      },
      "outputs": [],
      "source": [
        "clear_memory()\n",
        "\n",
        "tf.keras.backend.clear_session(); gc.collect()\n",
        "# Load the fine-tuned model with the LoRA-adapted weights\n",
        "fresh_lm = keras_hub.models.Gemma3CausalLM.from_preset(\"gemma3_instruct_1b\")\n",
        "fresh_lm.backbone.enable_lora(rank=16)   # must match the saved rank\n",
        "fresh_lm.backbone.load_lora_weights(\"lora_rank4_final.weights.lora.h5\")\n",
        "compile_with_sampler(fresh_lm, k=5, seed=SEED)\n",
        "\n",
        "sample_dialogue = \"\"\"Doctor: How are you feeling today?\n",
        "Patient: I'm still having chest pains.\n",
        "Doctor: Are they sharp or dull?\n",
        "Patient: More of a crushing pressure right here.\"\"\"\n",
        "\n",
        "prompt = TEMPLATE.format(\n",
        "    instruction=instruction,\n",
        "    dialogue= sample_dialogue\n",
        ")\n",
        "\n",
        "print(safe_generate(fresh_lm, prompt, max_new_tokens=1024))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01fe61fb",
      "metadata": {
        "id": "01fe61fb"
      },
      "source": [
        "## 🔧 Further Work\n",
        "\n",
        "- **Improve Model Performance**: Current results are promising but still limited. Fine-tuning with more epochs, experimenting with learning rates, or trying a higher LoRA rank could yield better summaries.\n",
        "- **Experiment with Alternatives**: Test other open models like Mistral or LLaMA on the same task. Consider combining LoRA with prompt engineering or instruction tuning.\n",
        "- **Dataset Enhancements**: Explore data augmentation, add more diverse dialogues, or filter noisy examples to improve generalization.\n",
        "- **Evaluation Improvements**: Integrate medical-specific metrics (e.g. clinical concept coverage) alongside ROUGE for deeper insight.\n",
        "\n",
        "🚀 Contributions and experiments are welcome — let’s build a stronger medical summarizer together!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97a5410e",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
